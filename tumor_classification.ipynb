{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tumor_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPTA+E71e4fZ8NTAeWXb+3u"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive connected.\")\n",
        "%cd ./drive/MyDrive/colab/tumor_classification/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-UwOy-Kn5yV",
        "outputId": "ac24d671-dbd0-4688-f468-53f3de210971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive connected.\n",
            "/content/drive/MyDrive/colab/tumor_classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d sartajbhuvaji/brain-tumor-classification-mri\n",
        "!mkdir data\n",
        "!unzip brain-tumor-classification-mri.zip -d data"
      ],
      "metadata": {
        "id": "HOW_86Ppn_-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeAk-9N3n_n-",
        "outputId": "349761a1-a729-43c9-9247-849b6da6c91f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing  Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "REBUILD_DATA = True\n",
        "\n",
        "class BrainTumorClassification():\n",
        "  IMG_SIZE = 512\n",
        "  GLIOMA = \"/data/Training/glioma_tumor\"\n",
        "  MENINGIOMA = \"/data/Training/meningioma_tumor\"\n",
        "  PITUITARY = \"/data/Training/pituitary_tumor\"\n",
        "  NO = \"/data/Training/no_tumor\"\n",
        "  TESTING_GLIOMA = \"/data/Testing/glioma_tumor\"\n",
        "  TESTING_MENINGIOMA = \"/data/Testing/meningioma_tumor\"\n",
        "  TESTING_PITUITARY = \"/data/Testing/pituitary_tumor\"\n",
        "  TESTING_NO = \"/data/Testing/no_tumor\"\n",
        "  LABELS = {'glioma_tumor':0, 'meningioma_tumor': 1, 'pituitary_tumor': 2, 'no_tumor': 3}\n",
        "  training_data = []\n",
        "  training_images = []\n",
        "  training_labels = []\n",
        "  testing_data = []\n",
        "  testing_images = []\n",
        "  testing_labels = []\n",
        "\n",
        "  def make_training_data(self):\n",
        "    for label in self.LABELS:\n",
        "      for f in tqdm(os.listdir(\"data/Training/\"+label)):\n",
        "        if \"jpg\" in f:\n",
        "          try:\n",
        "            path = \"data/Training/\"+os.path.join(label, f)\n",
        "            img = cv2.imread(path)\n",
        "            img = cv2.resize(img,(self.IMG_SIZE, self.IMG_SIZE))\n",
        "            self.training_images.append(img)\n",
        "            self.training_labels.append(self.LABELS[label])\n",
        "          except Exception as e:\n",
        "            pass\n",
        "    training_images, training_labels = shuffle(self.training_images, self.training_labels, random_state=0)\n",
        "    training_images = np.array(training_images)\n",
        "    training_labels = np.array(training_labels)\n",
        "    print(training_images.shape)\n",
        "    print(training_labels.shape)\n",
        "    np.save(\"training_images.npy\", training_images)\n",
        "    np.save(\"training_labels.npy\", training_labels)\n",
        "\n",
        "  \n",
        "  def make_testing_data(self):\n",
        "    for label in self.LABELS:\n",
        "      for f in tqdm(os.listdir(\"data/Testing/\"+label)):\n",
        "        if \"jpg\" in f:\n",
        "          try:\n",
        "            path = \"data/Testing/\"+os.path.join(label, f)\n",
        "            img = cv2.imread(path)\n",
        "            img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "            self.testing_images.append(img)\n",
        "            self.testing_labels.append(self.LABELS[label])\n",
        "          except Exception as e:\n",
        "            pass\n",
        "    testing_images, testing_labels = shuffle(self.testing_images, self.testing_labels, random_state=0)\n",
        "    testing_images = np.array(testing_images)\n",
        "    testing_labels = np.array(testing_labels)\n",
        "    print(testing_images.shape)\n",
        "    print(testing_labels.shape)\n",
        "    np.save(\"testing_images.npy\", testing_images)\n",
        "    np.save(\"testing_labels.npy\", testing_labels)\n",
        "if REBUILD_DATA:\n",
        "  btclass = BrainTumorClassification()\n",
        "  btclass.make_training_data()\n",
        "  btclass.make_testing_data()\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "774gPwj8eayV",
        "outputId": "03cebb6d-4e2b-444f-8fff-77a237b14277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 826/826 [00:10<00:00, 80.42it/s]\n",
            "100%|██████████| 822/822 [00:08<00:00, 94.75it/s] \n",
            "100%|██████████| 827/827 [00:07<00:00, 115.03it/s]\n",
            "100%|██████████| 395/395 [00:03<00:00, 127.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2870, 512, 512, 3)\n",
            "(2870,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 86.49it/s]\n",
            "100%|██████████| 115/115 [00:00<00:00, 125.33it/s]\n",
            "100%|██████████| 74/74 [00:01<00:00, 58.68it/s]\n",
            "100%|██████████| 105/105 [00:00<00:00, 179.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(394, 512, 512, 3)\n",
            "(394,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_images = np.load(\"training_images.npy\", allow_pickle=True)\n",
        "training_labels = np.load(\"training_labels.npy\", allow_pickle=True)\n",
        "\n",
        "testing_images = np.load(\"testing_images.npy\", allow_pickle=True)\n",
        "testing_labels = np.load(\"testing_labels.npy\", allow_pickle=True)\n",
        "\n",
        "print(\"Shape of training_images: \",(training_images).shape,\" | Shape of training_labels:\",(training_labels).shape,\"|| Shape of testing_images: \", (testing_images).shape ,\" | Shape of testing_labels:\",(testing_labels).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwQ6UhqG8U5B",
        "outputId": "16f38d5e-cf81-46fc-82af-ae14694284e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training_images:  (2870, 512, 512, 3)  | Shape of training_labels: (2870,) Shape of testing_images:  (394, 512, 512, 3)  | Shape of testing_labels: (394,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X = torch.Tensor([i for i in training_images]).view(-1,512,512)\n",
        "train_X = X/255.0\n",
        "train_y = torch.Tensor([i for i in training_labels])\n",
        "\n",
        "X2 = torch.Tensor([i for i in testing_images]).view(-1,512,512)\n",
        "test_X = X2/255.0\n",
        "test_y = torch.Tensor([i for i in testing_labels])\n",
        "\n",
        "print(len(train_X), len(test_X))\n",
        "\n",
        "plt.imshow(X[0], cmap=\"gray\")\n",
        "print(training_labels[0])"
      ],
      "metadata": {
        "id": "3sCiI_G-_ybG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOW-Q09VAu62",
        "outputId": "3150a019-0bd4-4208-d680-b768ebcb0926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on the GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models.mobilenet import mobilenet_v2\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "\n",
        "model = mobilenet_v2(pretrained=True)\n",
        "model.classifier[1] = torch.nn.Linear(in_features=model.classifier[1].in_features, out_features=4)\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "6jc9vsSJ7DKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model):\n",
        "  BATCH_SIZE = 100\n",
        "  EPOCHS = 10\n",
        "  for epoch in range(EPOCHS):\n",
        "    for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
        "      batch_X = train_X[i:i+BATCH_SIZE].view(-1, 3, 224, 224)\n",
        "      batch_y = train_y[i:i+BATCH_SIZE]\n",
        "\n",
        "      batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "      model.zero_grad()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(batch_X)\n",
        "      loss = loss_function(outputs, batch_y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "    print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
        "train(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "lLL-Uzp0CX1f",
        "outputId": "9c0cec0e-4bf5-4516-e357-b4c0d6a2bdb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/87 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-642129f1cf4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch: {epoch}. Loss: {loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-69-642129f1cf4c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mbatch_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 3, 224, 224]' is invalid for input of size 5017600"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gvQGtcEcCqAi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}